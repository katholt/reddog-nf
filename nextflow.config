includeConfig 'config/slurm_job.config'


manifest {
  description = 'RedDog mapping pipeline, nextflow implementation'
  author = 'Nextflow implementation: Stephen Watts; Original pipeline: David Edwards, Bernie Pope, Kat Holt'
  homePage = 'https://github.com/scwatts/reddog-nf'
  nextflowVersion = '>=20.01.0'
}


params {
  // Input and output
  reads = 'reads/*.fastq'
  reference = 'data/reference.gbk'
  output_dir = 'output/'
  run_info_dir = "${output_dir}/run_info/"


  // Merge run
  merge_run = false
  existing_run_dir = ''
  merge_ignore_errors = false


  // Optional stages
  subsample_reads = false
  subsample_read_count = 100000
  read_quality_report = false
  force_tree = false


  // General
  // Bowtie parameters
  bt2_max_frag_len = 2000
  bt2_mode = '--sensitive-local'

  // Minimum depth for variant filtering
  var_depth_min = 5

  // Mapping stats pass/fail
  mapping_cover_min = 50
  mapping_depth_min = 10
  mapping_mapped_min = 50

  // Ingroup/outgroup threshold modifier, calculated as:
  //   isolate(snps/coverage) <= data_set_mean(snps/coverage) + data_set_stddev(snps/coverage) * outgroup_mod
  outgroup_mod = 2

  // Allele matrix SNP support
  allele_matrix_support = 90

  // Allele matrix filtering
  allele_matrix_cons = 95


  // Executor
  // Maximum retries before ignoring job
  max_retries = 3
  // Maximum jobs to submit to the SLURM queue at once
  queue_size = 1000
  // Number of processors to use for local execution
  processors = 4
  // Account for SLURM
  slurm_account = 'js66'


  // Misc
  force = false
  help = false
}


profiles {
  massive {
    executor {
      name = 'slurm'
      // Queue size
      queueSize = params.queue_size
      // Submission rate to 2 per second
      submitRateLimit = '2/1.seconds'
      // Modify job-name, replace 'nf' with 'rd'
      // For whatever reason I can't access task.processor.name here so instead we do
      // a string sub to achieve desired result (nextflow 20.04.1)
      jobName = { "rd-${task.name}".replace(' ', '_') }
    }

    process {
      // Retry jobs - typically with more resources
      // NOTE: referencing task.maxRetries in the errorStrategy closure causes a recursion loop in nf
      // during task resubmission and crashes due to a stack overflow; must be specified as done below
      maxRetries = params.max_retries
      errorStrategy = { task.attempt < params.max_retries ? 'retry' : 'ignore' }

      // Required for consistent resumes on massives NFS
      cache = 'lenient'

      // Set options absent from nf slurm api
      clusterOptions = {
        qos = ''
        partition = ''
        if (task.time <= 30.minutes) {
          qos = 'genomics'
          partition = 'comp,genomics,short'
        } else if (task.time <= 240.minutes) {
          qos = 'genomics'
          partition = 'comp,genomics'
        } else {
          qos = 'normal'
          partition = 'comp'
        }
        return "--account=${params.slurm_account} --qos=${qos} --partition=${partition}"
      }
    }
  }

  standard {
    executor {
        name = 'local'
        queueSize = params.processors
    }
  }
}


// Nextflow run info outputs
dag {
  enabled = true
  file = "${params.run_info_dir}/nextflow/dag.svg"
}

report {
  enabled = true
  file = "${params.run_info_dir}/nextflow/report.html"
}

timeline {
  enabled = true
  file = "${params.run_info_dir}/nextflow/timeline.html"
}

trace {
  enabled = true
  file = "${params.run_info_dir}/nextflow/trace.txt"
}
