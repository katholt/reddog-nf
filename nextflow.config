manifest {
  description = 'RedDog mapping pipeline, nextflow implementation'
  author = 'Nextflow implementation: Stephen Watts; Original pipeline: David Edwards, Bernie Pope, Kat Holt'
  homePage = 'https://github.com/scwatts/reddog-nf'
  nextflowVersion = '>=20.01.0'
}

params {
  // Input and output
  reads = 'reads/*.fastq'
  reference = 'data/reference.gbk'
  output_dir = 'output/'
  run_info_dir = "${output_dir}/run_info/"


  // Merge run settings
  merge_run = false
  merge_ignore_errors = false
  previous_run_dir = ''


  // Optional stages
  subsample_reads = false
  subsample_read_count = 100000
  read_quality_report = false
  force_tree = false


  // General settings
  // Bowtie parameters
  bt2_max_frag_len = 2000
  bt2_mode = '--sensitive-local'

  // Minimum depth for variant filtering
  var_depth_min = 5

  // Mapping stats pass/fail
  mapping_cover_min = 50
  mapping_depth_min = 10
  mapping_mapped_min = 50

  // Ingroup/outgroup threshold modifier, calculated as:
  //   isolate(reads/coverage) <= data_set_mean(reads/coverage) + data_set_stddev(reads/coverage) * outgroup_mod
  outgroup_mod = 2

  // Allele matrix filtering conservation - alleles are filtered where less than n isolates have a known allele
  allele_matrix_cons = 95


  // Executor options
  // Maximum jobs to submit to the SLURM queue at once
  queue_size = 100
  // Number of processors to use for local execution
  processors = 4


  // Misc
  force = false
  help = false
}

profiles {
  standard {
    process {
      executor = 'local'
    }
  }

  massive {
    process {
      executor = 'slurm'

      // Retry jobs - typically with more resources
      errorStrategy = 'retry'
      maxRetries = 3

      // Required for consistent resumes on massives NFS
      cache = 'lenient'

      // Set options absent from nf slurm api
      clusterOptions = {
        account = 'js66'
        qos = ''
        partition = ''
        if (task.time <= 30.minutes) {
          qos = 'genomics'
          partition = 'comp,genomics,short'
        } else if (task.time <= 120.minutes) {
          qos = 'genomics'
          partition = 'comp,genomics'
        } else {
          qos = 'normal'
          partition = 'comp'
        }
        return "--account=${account} --qos=${qos} --partition=${partition}"
      }

      // Alignment and variant calling processes
      withName: align_reads_se {
        time = { 60.minutes * task.attempt }
        memory = { 4096.MB * task.attempt }
      }

      withName: align_reads_pe {
        time = { 60.minutes * task.attempt }
        memory = { 4096.MB * task.attempt }
      }

      withName: call_snps {
        time = { 60.minutes * task.attempt }
        memory = { 4096.MB * task.attempt }
      }

      // Mapping stats processes
      withName: calculate_gene_coverage_depth {
        time = { 60.minutes * task.attempt }
        memory = { 4096.MB * task.attempt }
      }

      withName: calculate_mapping_statistics {
        time = { 60.minutes * task.attempt }
        memory = { 4096.MB * task.attempt }
      }

      withName: aggregate_mapping_statistics {
        time = { 60.minutes * task.attempt }
        memory = { 4096.MB * task.attempt }
      }

      withName: get_passing_replicons {
        time = { 60.minutes * task.attempt }
        memory = { 4096.MB * task.attempt }
      }

      // Allele matrix processes
      withName: create_allele_matrix {
        time = { 60.minutes * task.attempt }
        memory = { 4096.MB * task.attempt }
      }

      withName: aggregate_allele_matrices {
        time = { 60.minutes * task.attempt }
        memory = { 4096.MB * task.attempt }
      }

      withName: filter_allele_matrix {
        time = { 60.minutes * task.attempt }
        memory = { 4096.MB * task.attempt }
      }

      // Other processes
      withName: prepare_reference {
        executor = 'local'
      }

      withName: subsample_reads_se {
        time = { 60.minutes * task.attempt }
        memory = { 4096.MB * task.attempt }
      }

      withName: subsample_reads_pe {
        time = { 60.minutes * task.attempt }
        memory = { 4096.MB * task.attempt }
      }

      withName: create_read_quality_report {
        time = { 60.minutes * task.attempt }
        memory = { 4096.MB * task.attempt }
      }

      withName: create_mpileups {
        time = { 60.minutes * task.attempt }
        memory = { 4096.MB * task.attempt }
      }

      withName: aggregate_snp_sites {
        time = { 60.minutes * task.attempt }
        memory = { 4096.MB * task.attempt }
      }

      withName: aggregate_read_quality_reports {
        time = { 60.minutes * task.attempt }
        memory = { 4096.MB * task.attempt }
      }

      withName: determine_coding_consequences {
        time = { 60.minutes * task.attempt }
        memory = { 4096.MB * task.attempt }
      }

      withName: create_snp_alignment {
        time = { 60.minutes * task.attempt }
        memory = { 4096.MB * task.attempt }
      }

      withName: infer_phylogeny {
        time = { 60.minutes * task.attempt }
        memory = { 4096.MB * task.attempt }
      }

      // Merge processes
      withName: merge:index_bam {
        time = { 60.minutes * task.attempt }
        memory = { 4096.MB * task.attempt }
      }

      withName: merge:gene_depth {
        time = { 60.minutes * task.attempt }
        memory = { 4096.MB * task.attempt }
      }

      withName: merge:gene_coverage {
        time = { 60.minutes * task.attempt }
        memory = { 4096.MB * task.attempt }
      }

      withName: merge:mapping_stats {
        time = { 60.minutes * task.attempt }
        memory = { 4096.MB * task.attempt }
      }

      withName: merge:collect_snp_sites {
        time = { 60.minutes * task.attempt }
        memory = { 4096.MB * task.attempt }
      }
    }
  }
}

dag {
  enabled = true
  file = "${params.run_info_dir}/nextflow/dag.svg"
}

report {
  enabled = true
  file = "${params.run_info_dir}/nextflow/report.html"
}

timeline {
  enabled = true
  file = "${params.run_info_dir}/nextflow/timeline.html"
}

trace {
  enabled = true
  file = "${params.run_info_dir}/nextflow/trace.txt"
}

// SLURM options
// Replace 'nf' in SLURM job name with 'rr'
// For whatever reason I can't access task.processor.name here so instead we do
// a string sub to achieve desired result
executor.$slurm.jobName = { "rr-${task.name}".replace(' ', '_') }
// Limit queue size (100 is default)
executor.$slurm.queueSize = params.queue_size

// Local executor options
executor.$local.queueSize = params.processors
